"""
Production-Ready Database Manager –¥–ª—è PostgreSQL
–ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Railpack/Dokploy
"""

import asyncio
import logging
import os
from datetime import datetime
from typing import List, Dict, Any, Optional
import asyncpg

logger = logging.getLogger(__name__)

class ProductionDatabaseManager:
    """Production-ready –º–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –º–∏–≥—Ä–∞—Ü–∏—è–º–∏"""
    
    def __init__(self):
        self.database_url = os.getenv('DATABASE_URL')
        if not self.database_url:
            raise ValueError("DATABASE_URL environment variable is required")
        
        self.connection_pool: Optional[asyncpg.Pool] = None
    
    async def verify_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL"""
        try:
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL...")
            
            # –°–æ–∑–¥–∞–µ–º –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            self.connection_pool = await asyncpg.create_pool(
                self.database_url,
                min_size=1,
                max_size=10,
                command_timeout=60
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
            async with self.connection_pool.acquire() as conn:
                await conn.fetchval('SELECT 1')
            
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}")
            raise
    
    async def run_safe_migrations(self) -> bool:
        """
        –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º –º–∏–≥—Ä–∞—Ü–∏–π
        """
        try:
            logger.info("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π...")
            
            if not self.connection_pool:
                await self.verify_connection()
            
            async with self.connection_pool.acquire() as conn:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
                existing_tables = await self._check_existing_tables(conn)
                
                if existing_tables:
                    logger.info(f"üìã –ù–∞–π–¥–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã: {', '.join(existing_tables)}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
                    has_data = await self._check_existing_data(conn, existing_tables)
                    
                    if has_data:
                        logger.info("üìä –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ - –≤—ã–ø–æ–ª–Ω—è–µ–º –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏")
                        await self._run_incremental_migrations(conn, existing_tables)
                    else:
                        logger.info("üìä –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
                        await self._run_full_initialization(conn)
                else:
                    logger.info("üìã –¢–∞–±–ª–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é")
                    await self._run_full_initialization(conn)
                
                # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                await self._create_performance_indexes(conn)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                await self._update_system_settings(conn)
            
            logger.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–π: {e}")
            raise
    
    async def _check_existing_tables(self, conn: asyncpg.Connection) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü"""
        try:
            query = """
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_type = 'BASE TABLE'
            """
            
            rows = await conn.fetch(query)
            return [row['table_name'] for row in rows]
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return []
    
    async def _check_existing_data(self, conn: asyncpg.Connection, tables: List[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö"""
        try:
            data_tables = ['users', 'payments', 'user_requests']
            
            for table in data_tables:
                if table in tables:
                    count = await conn.fetchval(f'SELECT COUNT(*) FROM {table}')
                    if count > 0:
                        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü–µ {table}")
                        return True
            
            return False
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}")
            return False
    
    async def _run_full_initialization(self, conn: asyncpg.Connection):
        """–ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üîÑ –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        # SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
        create_tables_sql = """
        -- –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        CREATE TABLE IF NOT EXISTS users (
            user_id BIGINT PRIMARY KEY,
            username VARCHAR(255),
            first_name VARCHAR(255),
            last_name VARCHAR(255),
            is_subscribed BOOLEAN DEFAULT FALSE,
            subscription_end TIMESTAMP,
            free_requests_used INTEGER DEFAULT 0,
            is_admin BOOLEAN DEFAULT FALSE,
            is_super_admin BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_activity TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_payment_date TIMESTAMP,
            payment_provider VARCHAR(50)
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ –ø–ª–∞—Ç–µ–∂–µ–π
        CREATE TABLE IF NOT EXISTS payments (
            id SERIAL PRIMARY KEY,
            user_id BIGINT REFERENCES users(user_id),
            payment_id VARCHAR(255) UNIQUE,
            amount INTEGER NOT NULL,
            currency VARCHAR(10) DEFAULT 'RUB',
            status VARCHAR(50) DEFAULT 'pending',
            invoice_payload TEXT,
            subscription_months INTEGER DEFAULT 1,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            cancellation_reason TEXT
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        CREATE TABLE IF NOT EXISTS user_requests (
            id SERIAL PRIMARY KEY,
            user_id BIGINT REFERENCES users(user_id),
            request_type VARCHAR(100),
            request_data JSONB,
            response_data JSONB,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ —Ä–∞—Å—Å—ã–ª–æ–∫
        CREATE TABLE IF NOT EXISTS broadcast_messages (
            id SERIAL PRIMARY KEY,
            title VARCHAR(255) NOT NULL,
            content TEXT NOT NULL,
            target_type VARCHAR(50) DEFAULT 'all',
            status VARCHAR(50) DEFAULT 'draft',
            scheduled_at TIMESTAMP,
            sent_at TIMESTAMP,
            total_sent INTEGER DEFAULT 0,
            total_delivered INTEGER DEFAULT 0,
            total_failed INTEGER DEFAULT 0,
            created_by BIGINT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        CREATE TABLE IF NOT EXISTS user_feedback (
            id SERIAL PRIMARY KEY,
            user_id BIGINT REFERENCES users(user_id),
            feedback_type VARCHAR(50),
            content TEXT,
            rating INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ –∫—ç—à–∞ –ø–æ–∏—Å–∫–∞ –∫–∞–Ω–∞–ª–æ–≤
        CREATE TABLE IF NOT EXISTS channel_search_cache (
            id SERIAL PRIMARY KEY,
            search_query VARCHAR(255),
            results JSONB,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            expires_at TIMESTAMP
        );
        
        -- –¢–∞–±–ª–∏—Ü–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        CREATE TABLE IF NOT EXISTS system_settings (
            key VARCHAR(255) PRIMARY KEY,
            value TEXT NOT NULL,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        
        await conn.execute(create_tables_sql)
        logger.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã")
    
    async def _run_incremental_migrations(self, conn: asyncpg.Connection, existing_tables: List[str]):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        logger.info("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π...")
        
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ç–∞–±–ª–∏—Ü
        required_tables = {
            'users', 'payments', 'user_requests', 'broadcast_messages',
            'user_feedback', 'channel_search_cache', 'system_settings'
        }
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã
        missing_tables = required_tables - set(existing_tables)
        
        if missing_tables:
            logger.info(f"üìã –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü: {', '.join(missing_tables)}")
            await self._run_full_initialization(conn)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ö–µ–º—ã
        await self._update_table_schemas(conn, existing_tables)
    
    async def _update_table_schemas(self, conn: asyncpg.Connection, existing_tables: List[str]):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ö–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–∞–±–ª–∏—Ü"""
        logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ö–µ–º —Ç–∞–±–ª–∏—Ü...")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ö–µ–º—ã
        schema_updates = [
            {
                'table': 'users',
                'column': 'payment_provider',
                'definition': 'VARCHAR(50)',
                'default': 'NULL'
            },
            {
                'table': 'payments',
                'column': 'cancellation_reason',
                'definition': 'TEXT',
                'default': 'NULL'
            },
            {
                'table': 'payments',
                'column': 'updated_at',
                'definition': 'TIMESTAMP',
                'default': 'CURRENT_TIMESTAMP'
            }
        ]
        
        for update in schema_updates:
            if update['table'] in existing_tables:
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                    check_query = """
                        SELECT column_name 
                        FROM information_schema.columns 
                        WHERE table_name = $1 AND column_name = $2
                    """
                    
                    result = await conn.fetchval(check_query, update['table'], update['column'])
                    
                    if not result:
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É
                        alter_query = f"""
                            ALTER TABLE {update['table']} 
                            ADD COLUMN {update['column']} {update['definition']} DEFAULT {update['default']}
                        """
                        await conn.execute(alter_query)
                        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ {update['column']} –≤ —Ç–∞–±–ª–∏—Ü—É {update['table']}")
                        
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É {update['table']}: {e}")
    
    async def _create_performance_indexes(self, conn: asyncpg.Connection):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_users_subscription ON users(is_subscribed, subscription_end)",
            "CREATE INDEX IF NOT EXISTS idx_users_admin ON users(is_admin, is_super_admin)",
            "CREATE INDEX IF NOT EXISTS idx_payments_status ON payments(status, created_at)",
            "CREATE INDEX IF NOT EXISTS idx_payments_user ON payments(user_id, status)",
            "CREATE INDEX IF NOT EXISTS idx_requests_user_date ON user_requests(user_id, created_at)",
            "CREATE INDEX IF NOT EXISTS idx_broadcast_status ON broadcast_messages(status, created_at)",
            "CREATE INDEX IF NOT EXISTS idx_cache_expires ON channel_search_cache(expires_at)"
        ]
        
        for index_sql in indexes:
            try:
                await conn.execute(index_sql)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å: {e}")
        
        logger.info("‚úÖ –ò–Ω–¥–µ–∫—Å—ã —Å–æ–∑–¥–∞–Ω—ã")
    
    async def _update_system_settings(self, conn: asyncpg.Connection):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
        try:
            settings = [
                ('database_version', '2.0.0', '–í–µ—Ä—Å–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö'),
                ('last_migration', datetime.now().isoformat(), '–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–∏–≥—Ä–∞—Ü–∏–∏'),
                ('production_mode', 'true', '–†–µ–∂–∏–º production'),
                ('migration_status', 'completed', '–°—Ç–∞—Ç—É—Å –º–∏–≥—Ä–∞—Ü–∏–π'),
                ('deployment_platform', 'railpack_dokploy', '–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–µ–ø–ª–æ—è')
            ]
            
            for key, value, description in settings:
                query = """
                    INSERT INTO system_settings (key, value, description, updated_at)
                    VALUES ($1, $2, $3, CURRENT_TIMESTAMP)
                    ON CONFLICT (key) DO UPDATE SET
                        value = EXCLUDED.value,
                        updated_at = CURRENT_TIMESTAMP
                """
                await conn.execute(query, key, value, description)
            
            logger.info("‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")
    
    async def optimize_for_production(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è production"""
        try:
            logger.info("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è production...")
            
            if not self.connection_pool:
                await self.verify_connection()
            
            async with self.connection_pool.acquire() as conn:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
                await conn.execute("ANALYZE")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                await conn.execute("VACUUM ANALYZE")
            
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è production")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    async def get_database_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if not self.connection_pool:
                await self.verify_connection()
            
            async with self.connection_pool.acquire() as conn:
                stats = {}
                
                # –†–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                db_size = await conn.fetchval("""
                    SELECT pg_size_pretty(pg_database_size(current_database()))
                """)
                stats['database_size'] = db_size
                
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
                tables = ['users', 'payments', 'user_requests', 'broadcast_messages']
                for table in tables:
                    try:
                        count = await conn.fetchval(f"SELECT COUNT(*) FROM {table}")
                        stats[f'{table}_count'] = count
                    except:
                        stats[f'{table}_count'] = 0
                
                # –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏
                active_subs = await conn.fetchval("""
                    SELECT COUNT(*) FROM users 
                    WHERE is_subscribed = TRUE 
                    AND (subscription_end IS NULL OR subscription_end > NOW())
                """)
                stats['active_subscriptions'] = active_subs
                
                return stats
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ë–î: {e}")
            return {}
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        if self.connection_pool:
            await self.connection_pool.close()
            logger.info("‚úÖ –ü—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π PostgreSQL –∑–∞–∫—Ä—ã—Ç")
